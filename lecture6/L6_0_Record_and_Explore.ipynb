{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c96193a",
   "metadata": {},
   "source": [
    "# EE 519 — Time-domain Analysis of speech (Notebook 0)\n",
    "## Record and Explore Speech in the Time Domain\n",
    "\n",
    "### What you’ll do\n",
    "1. **Load a provided WAV** (baseline) and/or **record your own speech** (optional).\n",
    "2. Record **vowels (voiced)**, **fricatives (unvoiced)**, and a **short sentence**, with **intentional silences**.\n",
    "3. Record **soft / normal / loud** to see amplitude effects.\n",
    "4. Visualize **nonstationarity** in the waveform and simple time-domain summaries.\n",
    "\n",
    "> **Tip for a clean recording:** speak for ~4–6 seconds and include ~1 seconds of silence at the start and end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac67b05",
   "metadata": {},
   "source": [
    "---\n",
    "## 0) Setup\n",
    "We’ll use only core scientific Python libraries.\n",
    "\n",
    "- If you can record from your laptop mic, we’ll try `sounddevice`.\n",
    "- If recording doesn’t work on your machine, **upload a WAV file** and proceed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 3)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "def to_mono(x):\n",
    "    \"\"\"Ensure mono float32 in [-1, 1].\"\"\"\n",
    "    x = np.asarray(x)\n",
    "    if x.ndim == 2:  # stereo -> mono\n",
    "        x = x.mean(axis=1)\n",
    "    if np.issubdtype(x.dtype, np.integer):\n",
    "        maxv = np.iinfo(x.dtype).max\n",
    "        x = x.astype(np.float32) / maxv\n",
    "    else:\n",
    "        x = x.astype(np.float32)\n",
    "    return np.clip(x, -1.0, 1.0)\n",
    "\n",
    "def remove_dc(x):\n",
    "    return x - np.mean(x)\n",
    "\n",
    "def peak_normalize(x, target=0.95):\n",
    "    peak = np.max(np.abs(x)) + 1e-12\n",
    "    return np.clip(x * (target / peak), -1.0, 1.0)\n",
    "\n",
    "def plot_waveform(x, fs, title=\"Waveform\", tlim=None):\n",
    "    t = np.arange(len(x)) / fs\n",
    "    plt.figure()\n",
    "    plt.plot(t, x, linewidth=0.8)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")    \n",
    "    plt.title(title)\n",
    "    if tlim is not None:\n",
    "        plt.xlim(tlim)\n",
    "    plt.show()\n",
    "\n",
    "def plot_zoom_grid(x, fs, regions, suptitle=\"Zoomed regions\"):\n",
    "    n = len(regions)\n",
    "    plt.figure(figsize=(12, 2.5*n))\n",
    "    for i, (label, t0, t1) in enumerate(regions, start=1):\n",
    "        a = int(max(0, t0*fs))\n",
    "        b = int(min(len(x), t1*fs))\n",
    "        t = np.arange(a, b) / fs\n",
    "        plt.subplot(n, 1, i)\n",
    "        plt.plot(t, x[a:b], linewidth=0.9)\n",
    "        plt.title(f\"{label}: {t0:.3f}–{t1:.3f} s\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Amp\")\n",
    "        plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(suptitle, y=1.02, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "def play_audio(x, fs):\n",
    "    display(Audio(x, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddeb5bf",
   "metadata": {},
   "source": [
    "---\n",
    "## 1) Load a WAV/record\n",
    "\n",
    "### Upload your own WAV\n",
    "Upload a file in your Jupyter environment (e.g.,`speech.wav`) and, place it in the same folder as this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Choose your audio file here ======\n",
    "wav_path = \"speech.wav\"  # <- change if needed\n",
    "\n",
    "if not os.path.exists(wav_path):\n",
    "    print(f\"File not found: {wav_path}\\nUpload a WAV and update wav_path.\")\n",
    "else:\n",
    "    fs, x = wavfile.read(wav_path)\n",
    "    x = to_mono(x)\n",
    "    print(\"Loaded:\", wav_path)\n",
    "    print(\"Sampling rate (Hz):\", fs)\n",
    "    print(\"Duration (s):\", len(x)/fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c4aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play and view the waveform (if loaded)\n",
    "if \"x\" in globals():\n",
    "    play_audio(x, fs)\n",
    "    plot_waveform(x, fs, title=f\"Waveform: {wav_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45d5471",
   "metadata": {},
   "source": [
    "---\n",
    "## 2)Record your own speech \n",
    "\n",
    "Record something like:\n",
    "- **Silence (1–2 s)**\n",
    "- **Voiced vowels**: “aaaa”, “iiii”, “oooo”\n",
    "- **Unvoiced fricatives**: “ssss”, “shhhh”\n",
    "- **Short sentence**: “Today is a sunny day.”\n",
    "- **Silence (1–2 s)**\n",
    "\n",
    "Then repeat for **soft**, **normal**, and **loud** voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to import sounddevice for microphone recording\n",
    "try:\n",
    "    import sounddevice as sd\n",
    "    SOUNDDEVICE_OK = True\n",
    "    print(\"sounddevice available ✅\")    \n",
    "except Exception as e:\n",
    "    SOUNDDEVICE_OK = False\n",
    "    print(\"sounddevice not available ❌\") \n",
    "    print(\"If you can't record, just use a WAV file and continue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(duration_s=8.0, fs=16000, channels=1):\n",
    "    \"\"\"Record audio from default microphone. Returns mono float32 signal.\"\"\"\n",
    "    if not SOUNDDEVICE_OK:\n",
    "        raise RuntimeError(\"sounddevice is not available on this system.\")\n",
    "    print(\"Recording... speak now!\")\n",
    "    y = sd.rec(int(duration_s * fs), samplerate=fs, channels=channels, dtype=\"float32\")\n",
    "    sd.wait()\n",
    "    y = y.squeeze()\n",
    "    print(\"Done.\")\n",
    "    return y, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9612bfe6-bfe5-48b5-8887-87586b1a554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record soft / normal / loud (optional)\n",
    "#Uncomment and run if your mic works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa491f-8987-432e-ae33-5ec35f99259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_soft, fs_rec = record_audio(duration_s=10, fs=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbac1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After recording:\n",
    "play_audio(y_soft, fs_rec)\n",
    "plot_waveform(y_soft, fs_rec, title=\"Recorded (normal)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a6153-4885-40e1-b1f7-a6ea4bea0aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_norm, fs_rec = record_audio(duration_s=10, fs=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1c412b-04dd-496c-906e-3068259e895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After recording:\n",
    "play_audio(y_norm, fs_rec)\n",
    "plot_waveform(y_norm, fs_rec, title=\"Recorded (normal)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2fe623-1072-4a8d-8000-f3f33f205701",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_loud, fs_rec = record_audio(duration_s=10, fs=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f25273-d2ed-469e-bab9-040cd64489a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After recording:\n",
    "play_audio(y_loud, fs_rec)\n",
    "plot_waveform(y_loud, fs_rec, title=\"Recorded (normal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a0eec6",
   "metadata": {},
   "source": [
    "---\n",
    "## 3) Compare soft / normal / loud (amplitude effects)\n",
    "If you recorded multiple takes, this section shows how amplitude changes.\n",
    "\n",
    "If you only loaded one WAV, you can still run the analysis using that single file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b152c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_signal(x, fs, name=\"signal\"):\n",
    "    x_dc = remove_dc(x)\n",
    "    rms = np.sqrt(np.mean(x_dc**2))\n",
    "    peak = np.max(np.abs(x_dc))\n",
    "    print(f\"{name}: duration={len(x)/fs:.2f}s | RMS={rms:.4f} | peak={peak:.4f}\")\n",
    "\n",
    "signals = []\n",
    "if \"x\" in globals():\n",
    "    signals.append((\"loaded\", x, fs))\n",
    "\n",
    "for var, label in [(\"y_soft\",\"soft\"),(\"y_norm\",\"normal\"),(\"y_loud\",\"loud\")]:\n",
    "    if var in globals():\n",
    "        signals.append((label, globals()[var], fs_rec))\n",
    "\n",
    "for name, sig, sfs in signals:\n",
    "    summarize_signal(sig, sfs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e64e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay waveforms for comparison (raw + peak-normalized)\n",
    "if len(signals) >= 2:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for name, sig, sfs in signals:\n",
    "        t = np.arange(len(sig)) / sfs\n",
    "        plt.plot(t, sig, linewidth=0.7, label=name)\n",
    "    plt.title(\"Overlay of recordings (raw amplitude)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for name, sig, sfs in signals:\n",
    "        sig_n = peak_normalize(remove_dc(sig))\n",
    "        t = np.arange(len(sig_n)) / sfs\n",
    "        plt.plot(t, sig_n, linewidth=0.7, label=name)\n",
    "    plt.title(\"Overlay of recordings (DC-removed + peak-normalized)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (normalized)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"(Skip) Need at least 2 signals (e.g., soft/normal/loud) to compare overlays.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158bcf90",
   "metadata": {},
   "source": [
    "---\n",
    "## 4) Nonstationarity: see how speech changes over time\n",
    "Speech is **nonstationary**: its properties change from silence → voiced → unvoiced → transitions.\n",
    "\n",
    "Below, we’ll:\n",
    "1. Plot the full waveform\n",
    "2. Zoom into a few regions (you choose time ranges)\n",
    "\n",
    "**Goal:** visually compare:\n",
    "- **silence** (low amplitude)\n",
    "- **voiced vowel** (quasi-periodic)\n",
    "- **unvoiced fricative** (noise-like)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which signal to explore\n",
    "if \"y_norm\" in globals():\n",
    "    sig_name, sig, fs_use = \"recorded_normal\", y_norm, fs_rec\n",
    "elif \"x\" in globals():\n",
    "    sig_name, sig, fs_use = \"loaded\", x, fs\n",
    "else:\n",
    "    raise RuntimeError(\"No audio available. Load a WAV or record audio.\")\n",
    "\n",
    "sig = to_mono(sig)\n",
    "sig = np.clip(sig, -1.0, 1.0)\n",
    "\n",
    "play_audio(sig, fs_use)\n",
    "plot_waveform(sig, fs_use, title=f\"Explore waveform: {sig_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9721b9",
   "metadata": {},
   "source": [
    "### Choose 3 regions to zoom\n",
    "Set three time intervals (in seconds):\n",
    "- **Silence** region\n",
    "- **Voiced vowel** region\n",
    "- **Unvoiced fricative** region\n",
    "\n",
    "> Tip: Use the full waveform plot above to estimate where these regions are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit these after looking at the waveform plot\n",
    "# regions = [\n",
    "#     (\"Silence region\", 0.5, 1.5),\n",
    "#     (\"Voiced vowel region\", 2.0, 2.2),\n",
    "#     (\"Unvoiced fricative region\", 3.0, 3.2),\n",
    "# ]\n",
    "\n",
    "regions = [\n",
    "    (\"Silence region\", 0, 0.8),\n",
    "    (\"Voiced vowel region\", 1.32, 1.38),\n",
    "    (\"Unvoiced fricative region\", 1.4, 1.44),\n",
    "]\n",
    "\n",
    "plot_zoom_grid(x, fs_use, regions, suptitle=f\"Zoomed regions: {sig_name}\")\n",
    "#plot_zoom_grid(x/max(abs(x)), fs_use, regions, suptitle=f\"Zoomed regions: {sig_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86775694-91ac-4196-9782-671f49f5bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(sig[int(0.5*fs_use):int(1.5*fs_use)], rate=fs_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060e672a",
   "metadata": {},
   "source": [
    "---\n",
    "## 5) Reflection questions (write your answers in a markdown cell)\n",
    "1. In your **voiced vowel region**, what visual evidence suggests quasi-periodicity?\n",
    "2. In your **unvoiced fricative region**, what visual evidence suggests noise-like behavior?\n",
    "3. Compare **soft vs loud** recordings: what changes? what stays similar?\n",
    "\n",
    "✅ When you’re done, move to **Notebook 1: Framing & Windowing**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106abc9-2f2e-474a-a186-94f5a54aff6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526a62a-69fb-49a3-a381-5e9437359b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85069d5a-c2df-4829-adfc-280a6e8ecb39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
