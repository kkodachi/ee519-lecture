{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2059bd18",
   "metadata": {},
   "source": [
    "# EE 519 ‚Äî Frequency-domain Analysis of Speech (Lectures 7-8)\n",
    "## Notebook ‚Äî STFT Parameter Lab (save outputs + compare clips)\n",
    "\n",
    "---\n",
    "## What you will do\n",
    "1. Choose 1‚Äì2 clips from your manifest.\n",
    "2. Sweep window length, hop, and nfft.\n",
    "3. Save key spectrograms.\n",
    "4. Write conclusions for speech analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d1c825",
   "metadata": {},
   "source": [
    "### How to use Lecture notebooks in-class (hands-on)\n",
    "**Goal:** build intuition for STFT by repeatedly analyzing *your own* recordings under different window/hop choices.\n",
    "\n",
    "**Workflow for the whole lecture**\n",
    "1. Record multiple clips once (Notebook 7.0) and they are saved + registered in a manifest.\n",
    "2. Every later notebook reuses the same recordings (no re-recording needed).\n",
    "3. Always pick **meaningful time regions** (vowel middle, fricative middle, stop burst, silence) ‚Äî not just the first frames.\n",
    "\n",
    "**Where things are saved**\n",
    "- Audio: `EE519_L7_Project/audio/`\n",
    "- Figures: `EE519_L7_Project/figures/`\n",
    "- Manifest: `EE519_L7_Project/manifest.json`\n",
    "\n",
    "**Pro tip:** keep filenames consistent across the class:  \n",
    "`vowel_a_soft`, `vowel_a_loud`, `sentence_fast`, `sentence_slow`, `fricative_s`, `stop_pa`, `silence_room`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996d1e5",
   "metadata": {},
   "source": [
    "### ‚úÖ Clip checklist (quick self-check)\n",
    "By the end of Notebook you should have **at least 8 clips** registered in your manifest:\n",
    "\n",
    "**Required categories**\n",
    "- **Vowel**: one steady vowel (e.g., /a/ or /i/) ‚Äî *soft* and *loud*\n",
    "- **Sentence**: one short sentence ‚Äî *slow* and *fast*\n",
    "- **Fricative**: sustained /s/ or /sh/\n",
    "- **Stop**: repeated /pa pa pa/ or /ta ta ta/ (captures bursts + closures)\n",
    "- **Silence**: 2‚Äì3 seconds of room silence\n",
    "\n",
    "If you're missing any, record them now in 7.0 (it takes 2-3 minutes and makes later analysis much clearer).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f48de6",
   "metadata": {},
   "source": [
    "## 0) Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e29daf",
   "metadata": {},
   "source": [
    "#### üéôÔ∏è Before you record: tips for clean data\n",
    "- Sit ~15‚Äì25 cm from the mic.\n",
    "- Avoid tapping the laptop/desk (low-frequency thumps).\n",
    "- Record at least **2‚Äì3 seconds** per clip.\n",
    "- For vowel: hold a steady pitch (don‚Äôt glide).\n",
    "- For sentence: keep content the same across slow/fast versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f3fbad",
   "metadata": {},
   "source": [
    "#### üíæ Save your artifacts\n",
    "Saving plots helps you build a personal ‚Äúspeech atlas‚Äù you can review before exams/projects.\n",
    "If your saved figures folder is empty, check:\n",
    "- you ran the plotting cell\n",
    "- the notebook has write permission in the current folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43090ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import get_window, chirp\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 3)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "# ---------------------------\n",
    "# Project folders (auto-create)\n",
    "# ---------------------------\n",
    "PROJECT_DIR = Path(\"EE519_L7_Project\")\n",
    "AUDIO_DIR   = PROJECT_DIR / \"audio\"\n",
    "FIG_DIR     = PROJECT_DIR / \"figures\"\n",
    "RESULTS_DIR = PROJECT_DIR / \"results\"\n",
    "for d in [PROJECT_DIR, AUDIO_DIR, FIG_DIR, RESULTS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MANIFEST_PATH = PROJECT_DIR / \"manifest.json\"\n",
    "\n",
    "def _to_float_mono(y):\n",
    "    \"\"\"Convert audio array to float32 mono in [-1, 1].\"\"\"\n",
    "    y = np.asarray(y)\n",
    "    if y.ndim == 2:\n",
    "        y = y.mean(axis=1)\n",
    "    if np.issubdtype(y.dtype, np.integer):\n",
    "        y = y.astype(np.float32) / (np.iinfo(y.dtype).max + 1e-12)\n",
    "    else:\n",
    "        y = y.astype(np.float32)\n",
    "    mx = np.max(np.abs(y)) + 1e-12\n",
    "    if mx > 1.0:\n",
    "        y = y / mx\n",
    "    return y\n",
    "\n",
    "def load_wav(path):\n",
    "    fs, y = wavfile.read(path)\n",
    "    return fs, _to_float_mono(y)\n",
    "\n",
    "def save_wav(path, fs, y):\n",
    "    \"\"\"Save float audio in [-1,1] to 16-bit PCM WAV.\"\"\"\n",
    "    y16 = np.clip(y, -1.0, 1.0)\n",
    "    y16 = (y16 * 32767).astype(np.int16)\n",
    "    wavfile.write(str(path), fs, y16)\n",
    "\n",
    "def play_audio(y, fs, label=None):\n",
    "    if label:\n",
    "        print(label)\n",
    "    display(Audio(y, rate=fs))\n",
    "\n",
    "def plot_waveform(y, fs, title=\"Waveform\", tlim=None, save_as=None):\n",
    "    t = np.arange(len(y)) / fs\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(t, y, linewidth=1)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.title(title)\n",
    "    if tlim is not None:\n",
    "        plt.xlim(tlim)\n",
    "    if save_as is not None:\n",
    "        out = FIG_DIR / save_as\n",
    "        plt.savefig(out, dpi=160, bbox_inches=\"tight\")\n",
    "        print(\"Saved figure ->\", out)\n",
    "    plt.show()\n",
    "\n",
    "def mag_spectrum(y, fs, nfft=None, db=True):\n",
    "    y = np.asarray(y, dtype=np.float32)\n",
    "    if nfft is None:\n",
    "        nfft = int(2**np.ceil(np.log2(len(y))))\n",
    "    Y = fft(y, n=nfft)\n",
    "    f = fftfreq(nfft, d=1/fs)\n",
    "    idx = f >= 0\n",
    "    mag = np.abs(Y[idx])\n",
    "    if db:\n",
    "        mag = 20*np.log10(mag + 1e-10)\n",
    "    return f[idx], mag\n",
    "\n",
    "def plot_spectrum(y, fs, title=\"Magnitude Spectrum\", fmax=None, nfft=None, db=True, save_as=None):\n",
    "    f, mag = mag_spectrum(y, fs, nfft=nfft, db=db)\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(f, mag, linewidth=1)\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Magnitude (dB)\" if db else \"Magnitude\")\n",
    "    plt.title(title)\n",
    "    if fmax is not None:\n",
    "        plt.xlim(0, fmax)\n",
    "    if save_as is not None:\n",
    "        out = FIG_DIR / save_as\n",
    "        plt.savefig(out, dpi=160, bbox_inches=\"tight\")\n",
    "        print(\"Saved figure ->\", out)\n",
    "    plt.show()\n",
    "\n",
    "def rms(y):\n",
    "    y = np.asarray(y, dtype=np.float32)\n",
    "    return float(np.sqrt(np.mean(y**2) + 1e-12))\n",
    "\n",
    "def add_white_noise(y, snr_db, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.asarray(y, dtype=np.float32)\n",
    "    sig_pwr = np.mean(y**2) + 1e-12\n",
    "    noise_pwr = sig_pwr / (10**(snr_db/10))\n",
    "    noise = rng.standard_normal(len(y), dtype=np.float32) * np.sqrt(noise_pwr)\n",
    "    return y + noise\n",
    "\n",
    "def select_segment(y, fs, start_s, end_s):\n",
    "    s = int(start_s*fs); e = int(end_s*fs)\n",
    "    s = max(0, min(s, len(y)))\n",
    "    e = max(0, min(e, len(y)))\n",
    "    if e <= s:\n",
    "        raise ValueError(\"end_s must be > start_s and within signal duration.\")\n",
    "    return y[s:e]\n",
    "\n",
    "# ---------------------------\n",
    "# Recording utilities\n",
    "# ---------------------------\n",
    "SOUNDDEVICE_OK = False\n",
    "try:\n",
    "    import sounddevice as sd\n",
    "    SOUNDDEVICE_OK = True\n",
    "except Exception:\n",
    "    SOUNDDEVICE_OK = False\n",
    "\n",
    "def record_audio(seconds=3.0, fs=16000, channels=1):\n",
    "    if not SOUNDDEVICE_OK:\n",
    "        raise RuntimeError(\"sounddevice not available. Upload WAVs or install sounddevice locally.\")\n",
    "    print(f\"Recording {seconds:.1f}s at {fs} Hz... (speak now)\")\n",
    "    y = sd.rec(int(seconds*fs), samplerate=fs, channels=channels, dtype='float32')\n",
    "    sd.wait()\n",
    "    y = _to_float_mono(y)\n",
    "    print(\"Done. RMS:\", rms(y))\n",
    "    return fs, y\n",
    "\n",
    "def load_manifest():\n",
    "    if MANIFEST_PATH.exists():\n",
    "        return json.loads(MANIFEST_PATH.read_text(encoding=\"utf-8\"))\n",
    "    return {\"audio_clips\": [], \"notes\": []}\n",
    "\n",
    "def save_manifest(m):\n",
    "    MANIFEST_PATH.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def register_clip(name, path, fs, duration_s, tags=None, notes=\"\"):\n",
    "    m = load_manifest()\n",
    "    m[\"audio_clips\"].append({\n",
    "        \"name\": name,\n",
    "        \"path\": str(path),\n",
    "        \"fs\": fs,\n",
    "        \"duration_s\": float(duration_s),\n",
    "        \"tags\": tags or [],\n",
    "        \"notes\": notes\n",
    "    })\n",
    "    save_manifest(m)\n",
    "\n",
    "def list_clips():\n",
    "    m = load_manifest()\n",
    "    if len(m[\"audio_clips\"]) == 0:\n",
    "        print(\"No clips registered yet.\")\n",
    "        return\n",
    "    for i, c in enumerate(m[\"audio_clips\"]):\n",
    "        print(f\"[{i}] {c['name']} | {c['duration_s']:.2f}s | fs={c['fs']} | tags={c['tags']} | file={c['path']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66e33a",
   "metadata": {},
   "source": [
    "#### üîß Optional automated check (run anytime)\n",
    "This cell reads your `manifest.json` and tells you what clip types you might be missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated checklist (uses tags and/or names)\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "\n",
    "MANIFEST_PATH = Path(\"EE519_L7_Project/manifest.json\")\n",
    "if not MANIFEST_PATH.exists():\n",
    "    print(\"No manifest found yet. Run Notebook 7.0 and record at least one clip.\")\n",
    "else:\n",
    "    m = json.loads(MANIFEST_PATH.read_text(encoding=\"utf-8\"))\n",
    "    clips = m.get(\"audio_clips\", [])\n",
    "    names = [c.get(\"name\",\"\").lower() for c in clips]\n",
    "    tags  = [set([t.lower() for t in c.get(\"tags\",[])]) for c in clips]\n",
    "\n",
    "    def has(pattern):\n",
    "        rgx = re.compile(pattern)\n",
    "        return any(rgx.search(n) for n in names)\n",
    "\n",
    "    def has_tag(t):\n",
    "        return any(t in tg for tg in tags)\n",
    "\n",
    "    req = {\n",
    "        \"vowel (soft)\": has(\"vowel\") and (has(\"soft\") or has_tag(\"soft\")),\n",
    "        \"vowel (loud)\": has(\"vowel\") and (has(\"loud\") or has_tag(\"loud\")),\n",
    "        \"sentence (slow)\": has(\"sentence\") and (has(\"slow\") or has_tag(\"slow\")),\n",
    "        \"sentence (fast)\": has(\"sentence\") and (has(\"fast\") or has_tag(\"fast\")),\n",
    "        \"fricative\": has(\"fric\") or has(\"s_\") or has_tag(\"fricative\"),\n",
    "        \"stop/burst\": has(\"stop\") or has(\"pa\") or has(\"ta\") or has_tag(\"stop\"),\n",
    "        \"silence\": has(\"silence\") or has_tag(\"silence\"),\n",
    "    }\n",
    "\n",
    "    print(\"Manifest clips:\", len(clips))\n",
    "    missing = [k for k,v in req.items() if not v]\n",
    "    if not missing:\n",
    "        print(\"‚úÖ Looks good ‚Äî you have the recommended set.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Missing (recommended):\")\n",
    "        for k in missing:\n",
    "            print(\" -\", k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5f8947",
   "metadata": {},
   "source": [
    "#### üîç Before you run: what will change when you change window/hop?\n",
    "- **Short window** ‚Üí better **time** resolution, blurrier frequency (wideband look)\n",
    "- **Long window** ‚Üí better **frequency** resolution, blurrier time (narrowband look)\n",
    "- **Smaller hop** ‚Üí more overlap ‚Üí smoother time evolution, more computation\n",
    "\n",
    "**Common issues**\n",
    "- If harmonics look ‚Äúfuzzy‚Äù: increase window length (for narrowband).\n",
    "- If stop bursts look ‚Äúsmeared‚Äù: shorten window (for wideband).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f19519",
   "metadata": {},
   "source": [
    "#### üéØ Action: pick *meaningful* time points (not sequential frames)\n",
    "Use the waveform/spectrogram to pick times from **different phenomena**:\n",
    "- vowel middle\n",
    "- fricative middle\n",
    "- stop burst peak\n",
    "- silence/closure\n",
    "\n",
    "**Why?** You want to compare spectra across *sound types*, not across adjacent time slices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb5eda0",
   "metadata": {},
   "source": [
    "#### üíæ Save your artifacts\n",
    "Saving plots helps you build a personal ‚Äúspeech atlas‚Äù you can review before exams/projects.\n",
    "If your saved figures folder is empty, check:\n",
    "- you ran the plotting cell\n",
    "- the notebook has write permission in the current folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6201559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_manual(y, fs, win_length_ms=25, hop_ms=10, window=\"hann\", nfft=None, center=False):\n",
    "    \"\"\"Manual STFT (analysis only). Returns f (Hz), t (s), X (frames x freqs), meta.\"\"\"\n",
    "    y = np.asarray(y, dtype=np.float32)\n",
    "    N = int(round(win_length_ms * 1e-3 * fs))\n",
    "    H = int(round(hop_ms * 1e-3 * fs))\n",
    "    if N <= 0 or H <= 0:\n",
    "        raise ValueError(\"Window length and hop must be positive.\")\n",
    "    if nfft is None:\n",
    "        nfft = int(2**np.ceil(np.log2(N)))\n",
    "    if nfft < N:\n",
    "        raise ValueError(\"nfft must be >= N.\")\n",
    "    w = get_window(window, N, fftbins=True).astype(np.float32)\n",
    "    if center:\n",
    "        pad = N // 2\n",
    "        y = np.pad(y, (pad, pad), mode=\"constant\")\n",
    "    num_frames = 1 + (len(y) - N) // H\n",
    "    if num_frames <= 0:\n",
    "        raise ValueError(\"Signal too short for chosen window length.\")\n",
    "    X = np.empty((num_frames, nfft//2 + 1), dtype=np.complex64)\n",
    "    for m in range(num_frames):\n",
    "        start = m * H\n",
    "        frame = y[start:start+N] * w\n",
    "        X[m, :] = np.fft.rfft(frame, n=nfft)\n",
    "    f = np.fft.rfftfreq(nfft, d=1/fs)\n",
    "    t = (np.arange(num_frames) * H) / fs\n",
    "    meta = {\"N\": N, \"H\": H, \"nfft\": nfft, \"window\": window, \"center\": center,\n",
    "            \"win_length_ms\": win_length_ms, \"hop_ms\": hop_ms}\n",
    "    return f, t, X, meta\n",
    "\n",
    "def spec_db(X):\n",
    "    return 20*np.log10(np.abs(X) + 1e-10)\n",
    "\n",
    "def plot_spectrogram_db(f, t, X, title=\"Spectrogram (dB)\", fmax=None, vmin=None, vmax=None, save_as=None):\n",
    "    S = spec_db(X)  # frames x freqs\n",
    "    plt.figure(figsize=(12, 4.5))\n",
    "    plt.imshow(S.T, origin=\"lower\", aspect=\"auto\",\n",
    "               extent=[t[0], t[-1], f[0], f[-1]],\n",
    "               vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar(label=\"dB\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.title(title)\n",
    "    if fmax is not None:\n",
    "        plt.ylim(0, fmax)\n",
    "    if save_as is not None:\n",
    "        out = FIG_DIR / save_as\n",
    "        plt.savefig(out, dpi=160, bbox_inches=\"tight\")\n",
    "        print(\"Saved figure ->\", out)\n",
    "    plt.show()\n",
    "\n",
    "def frame_index_from_time(t_sec, fs, hop_ms):\n",
    "    H = int(round(hop_ms * 1e-3 * fs))\n",
    "    return int(round(t_sec * fs / H))\n",
    "\n",
    "def plot_frame_spectrum_from_stft(f, X, frame_idx, title=\"\", fmax=None, save_as=None):\n",
    "    mag_db = 20*np.log10(np.abs(X[frame_idx]) + 1e-10)\n",
    "    plt.figure(figsize=(12,3))\n",
    "    plt.plot(f, mag_db, linewidth=1)\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Magnitude (dB)\")\n",
    "    plt.title(title + f\" (frame={frame_idx})\")\n",
    "    if fmax is not None:\n",
    "        plt.xlim(0, fmax)\n",
    "    if save_as is not None:\n",
    "        out = FIG_DIR / save_as\n",
    "        plt.savefig(out, dpi=160, bbox_inches=\"tight\")\n",
    "        print(\"Saved figure ->\", out)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939d8cf",
   "metadata": {},
   "source": [
    "---\n",
    "## 1) Choose one or two clips\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967ca93",
   "metadata": {},
   "source": [
    "#### ‚úÖ Checkpoint: choose clips you can explain\n",
    "Pick clips where you can point to regions like:\n",
    "- steady **vowel** (voiced)  \n",
    "- sustained **/s/** (unvoiced)  \n",
    "- **stop burst** (brief)  \n",
    "- **silence/closure** (low energy)\n",
    "\n",
    "**In-class goal:** you should be able to say ‚Äúthis region is voiced/unvoiced/stop/silence‚Äù *before* plotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef24a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_clips()\n",
    "clip_indices = [0]  # TODO: e.g., [vowel_index, fricative_index]\n",
    "\n",
    "m = load_manifest()\n",
    "clips = []\n",
    "for idx in clip_indices:\n",
    "    if idx < len(m[\"audio_clips\"]):\n",
    "        clips.append(m[\"audio_clips\"][idx])\n",
    "print(\"Chosen:\", [c[\"name\"] for c in clips])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f4cf7",
   "metadata": {},
   "source": [
    "---\n",
    "## 2) Parameter sweeps\n",
    "### A) Window length sweep (hop fixed)\n",
    "Try win = 10,20,30,40ms; hop=10ms.\n",
    "\n",
    "**What to look for:**\n",
    "- Harmonics (voiced) clarity vs transient smearing\n",
    "- Unvoiced broadband texture\n",
    "\n",
    "We save each spectrogram automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02797325",
   "metadata": {},
   "source": [
    "#### üîç Before you run: what will change when you change window/hop?\n",
    "- **Short window** ‚Üí better **time** resolution, blurrier frequency (wideband look)\n",
    "- **Long window** ‚Üí better **frequency** resolution, blurrier time (narrowband look)\n",
    "- **Smaller hop** ‚Üí more overlap ‚Üí smoother time evolution, more computation\n",
    "\n",
    "**Common issues**\n",
    "- If harmonics look ‚Äúfuzzy‚Äù: increase window length (for narrowband).\n",
    "- If stop bursts look ‚Äúsmeared‚Äù: shorten window (for wideband).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb14ff",
   "metadata": {},
   "source": [
    "#### üíæ Save your artifacts\n",
    "Saving plots helps you build a personal ‚Äúspeech atlas‚Äù you can review before exams/projects.\n",
    "If your saved figures folder is empty, check:\n",
    "- you ran the plotting cell\n",
    "- the notebook has write permission in the current folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_ms = 10\n",
    "for c in clips:\n",
    "    fs, y = load_wav(c[\"path\"])\n",
    "    for win_ms in [10, 20, 30, 40]:\n",
    "        f, tt, X, meta = stft_manual(y, fs, win_length_ms=win_ms, hop_ms=hop_ms, window=\"hann\", nfft=None, center=False)\n",
    "        plot_spectrogram_db(f, tt, X,\n",
    "                            title=f\"{c['name']} | win={win_ms}ms hop={hop_ms}ms\",\n",
    "                            fmax=min(8000, fs/2),\n",
    "                            save_as=f\"L7_3_{c['name']}_win{win_ms}ms.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072f91bf",
   "metadata": {},
   "source": [
    "---\n",
    "### B) Hop sweep (window fixed)\n",
    "Fix win=25ms; hop=2.5,5,10,20ms.\n",
    "\n",
    "**What to look for:** time sampling density and smoothness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc2022",
   "metadata": {},
   "source": [
    "#### üîç Before you run: what will change when you change window/hop?\n",
    "- **Short window** ‚Üí better **time** resolution, blurrier frequency (wideband look)\n",
    "- **Long window** ‚Üí better **frequency** resolution, blurrier time (narrowband look)\n",
    "- **Smaller hop** ‚Üí more overlap ‚Üí smoother time evolution, more computation\n",
    "\n",
    "**Common issues**\n",
    "- If harmonics look ‚Äúfuzzy‚Äù: increase window length (for narrowband).\n",
    "- If stop bursts look ‚Äúsmeared‚Äù: shorten window (for wideband).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee38e84f",
   "metadata": {},
   "source": [
    "#### üíæ Save your artifacts\n",
    "Saving plots helps you build a personal ‚Äúspeech atlas‚Äù you can review before exams/projects.\n",
    "If your saved figures folder is empty, check:\n",
    "- you ran the plotting cell\n",
    "- the notebook has write permission in the current folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc3df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_ms = 25\n",
    "for c in clips:\n",
    "    fs, y = load_wav(c[\"path\"])\n",
    "    for hop_ms in [2.5, 5, 10, 20]:\n",
    "        f, tt, X, meta = stft_manual(y, fs, win_length_ms=win_ms, hop_ms=hop_ms, window=\"hann\", nfft=None, center=False)\n",
    "        plot_spectrogram_db(f, tt, X,\n",
    "                            title=f\"{c['name']} | win={win_ms}ms hop={hop_ms}ms\",\n",
    "                            fmax=min(8000, fs/2),\n",
    "                            save_as=f\"L7_3_{c['name']}_hop{str(hop_ms).replace('.','p')}ms.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba1498",
   "metadata": {},
   "source": [
    "---\n",
    "### C) FFT size sweep\n",
    "Fix win=25ms hop=10ms; compare nfft=N, 2N, 4N.\n",
    "\n",
    "**Reminder:** more bins ‚â† more true resolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0e2d8",
   "metadata": {},
   "source": [
    "#### üîç Before you run: what will change when you change window/hop?\n",
    "- **Short window** ‚Üí better **time** resolution, blurrier frequency (wideband look)\n",
    "- **Long window** ‚Üí better **frequency** resolution, blurrier time (narrowband look)\n",
    "- **Smaller hop** ‚Üí more overlap ‚Üí smoother time evolution, more computation\n",
    "\n",
    "**Common issues**\n",
    "- If harmonics look ‚Äúfuzzy‚Äù: increase window length (for narrowband).\n",
    "- If stop bursts look ‚Äúsmeared‚Äù: shorten window (for wideband).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e684ee",
   "metadata": {},
   "source": [
    "#### üíæ Save your artifacts\n",
    "Saving plots helps you build a personal ‚Äúspeech atlas‚Äù you can review before exams/projects.\n",
    "If your saved figures folder is empty, check:\n",
    "- you ran the plotting cell\n",
    "- the notebook has write permission in the current folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_ms, hop_ms = 25, 10\n",
    "for c in clips:\n",
    "    fs, y = load_wav(c[\"path\"])\n",
    "    N = int(round(win_ms*1e-3*fs))\n",
    "    for mult in [1,2,4]:\n",
    "        nfft = int(2**np.ceil(np.log2(mult*N)))\n",
    "        f, tt, X, meta = stft_manual(y, fs, win_length_ms=win_ms, hop_ms=hop_ms, window=\"hann\", nfft=nfft, center=False)\n",
    "        plot_spectrogram_db(f, tt, X,\n",
    "                            title=f\"{c['name']} | win={win_ms}ms hop={hop_ms}ms nfft={nfft}\",\n",
    "                            fmax=min(8000, fs/2),\n",
    "                            save_as=f\"L7_3_{c['name']}_nfft{nfft}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d895e3",
   "metadata": {},
   "source": [
    "---\n",
    "## Reflection (required)\n",
    "Write in sentences:\n",
    "- For vowels (voiced), which settings made harmonics clearest? Why?\n",
    "- For fricatives (unvoiced), which settings made broadband energy most interpretable? Why?\n",
    "- What hop size was ‚Äúgood enough‚Äù for visual smoothness?\n",
    "- What did increasing nfft change (and not change)?\n",
    "\n",
    "### What‚Äôs next\n",
    "Notebook: wideband vs narrowband ‚Äútwo lenses‚Äù for speech.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2551fce",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ End-of-notebook wrap-up\n",
    "**Reflection (write in sentences):**\n",
    "- What parameter change produced the *biggest visible difference* today?\n",
    "- Which plot helped you most: waveform, spectrum, or spectrogram ‚Äî and why?\n",
    "- Name one mistake you made (or could make) and how you would debug it.\n",
    "\n",
    "**What‚Äôs next:** proceed to the next Lecture notebook and reuse the same saved recordings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776b4ea-2691-49c4-8218-028ac1428112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
